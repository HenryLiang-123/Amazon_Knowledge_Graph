{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21c0914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from mrtparse import *\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import gzip\n",
    "import shutil\n",
    "import openai\n",
    "\n",
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "934c10f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have successfully set up OPENAI_API_KEY as an environment variable.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "name = 'OPENAI_API_KEY'\n",
    "\n",
    "key_location = \"/Users/kiranjyothisheena/Documents/Kiran_Files/Capstone/OpenAPI_Key\"\n",
    "key_file = open(key_location, \"r\")\n",
    "openapi_key = key_file.readline()\n",
    "\n",
    "#secret = getpass.getpass(\"Enter the OpenAI API Key\")\n",
    "os.environ[name] = openapi_key\n",
    "print(f\"Have successfully set up {name} as an environment variable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e05b2db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your API key (keep it secret!)\n",
    "openai.api_key = openapi_key\n",
    "API_KEY = openapi_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b5ad26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd481900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Neo4j database\n",
    "uri = \"neo4j+s://28e5b287.databases.neo4j.io\"  # Change to match your Neo4j server settings\n",
    "username = \"neo4j\"      # Change to your Neo4j username\n",
    "password = \"z9J3DPCCxGYELn99XDdFbFIBnWOwR5fdn4MiG_Nvdck\"      # Change to your Neo4j password\n",
    "\n",
    "# Create a Neo4j driver\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bfd233",
   "metadata": {},
   "source": [
    "## Get Schema of graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55323f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "def neo4j_query(query: str, params: dict = {}) -> List[Dict[str, Any]]:\n",
    "\n",
    "    \"\"\"Query Neo4j database.\"\"\"\n",
    "    from neo4j.exceptions import CypherSyntaxError\n",
    "\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        try:\n",
    "            data = session.run(query, params)\n",
    "            return [r.data() for r in data]\n",
    "        except CypherSyntaxError as e:\n",
    "            raise ValueError(f\"Generated Cypher Statement is not valid\\n{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b971bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_schema() -> str:\n",
    "    \"\"\"\n",
    "    Refreshes the Neo4j graph schema information.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    node_properties_query = \"\"\"\n",
    "    CALL apoc.meta.data()\n",
    "    YIELD label, other, elementType, type, property\n",
    "    WHERE NOT type = \"RELATIONSHIP\" AND elementType = \"node\"\n",
    "    WITH label AS nodeLabels, collect({property:property, type:type}) AS properties\n",
    "    RETURN {labels: nodeLabels, properties: properties} AS output\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    rel_properties_query = \"\"\"\n",
    "    CALL apoc.meta.data()\n",
    "    YIELD label, other, elementType, type, property\n",
    "    WHERE NOT type = \"RELATIONSHIP\" AND elementType = \"relationship\"\n",
    "    WITH label AS nodeLabels, collect({property:property, type:type}) AS properties\n",
    "    RETURN {type: nodeLabels, properties: properties} AS output\n",
    "    \"\"\"\n",
    "\n",
    "    rel_query = \"\"\"\n",
    "    CALL apoc.meta.data()\n",
    "    YIELD label, other, elementType, type, property\n",
    "    WHERE type = \"RELATIONSHIP\" AND elementType = \"node\"\n",
    "    UNWIND other AS other_node\n",
    "    RETURN {start: label, type: property, end: toString(other_node)} AS output\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    node_properties = [el[\"output\"] for el in neo4j_query(node_properties_query)]\n",
    "    rel_properties = [el[\"output\"] for el in neo4j_query(rel_properties_query)]\n",
    "    relationships = [el[\"output\"] for el in neo4j_query(rel_query)]\n",
    "\n",
    "    structured_schema = {\n",
    "        \"node_props\": {el[\"labels\"]: el[\"properties\"] for el in node_properties},\n",
    "        \"rel_props\": {el[\"type\"]: el[\"properties\"] for el in rel_properties},\n",
    "        \"relationships\": relationships,\n",
    "    }\n",
    "    schema_str = f\"\"\"\n",
    "    Node properties are the following:\n",
    "    {node_properties}\n",
    "    Relationship properties are the following:\n",
    "    {rel_properties}\n",
    "    The relationships are the following:\n",
    "    {[f\"(:{el['start']})-[:{el['type']}]->(:{el['end']})\" for el in relationships]}\n",
    "    \"\"\"\n",
    "    \n",
    "    return schema_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57c4583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_str = refresh_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be129a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Node properties are the following:\n",
      "    [{'labels': 'Node', 'properties': [{'property': 'id', 'type': 'STRING'}, {'property': 'as_name', 'type': 'STRING'}, {'property': 'org_name', 'type': 'STRING'}, {'property': 'country', 'type': 'STRING'}, {'property': 'upstream', 'type': 'STRING'}, {'property': 'downstream', 'type': 'STRING'}, {'property': 'rank', 'type': 'STRING'}, {'property': 'city', 'type': 'STRING'}, {'property': 'state', 'type': 'STRING'}]}, {'labels': 'Node_2', 'properties': [{'property': 'id', 'type': 'STRING'}, {'property': 'as_name', 'type': 'STRING'}, {'property': 'org_name', 'type': 'STRING'}, {'property': 'country', 'type': 'STRING'}, {'property': 'upstream', 'type': 'STRING'}, {'property': 'downstream', 'type': 'STRING'}, {'property': 'rank', 'type': 'STRING'}, {'property': 'city', 'type': 'STRING'}, {'property': 'state', 'type': 'STRING'}]}]\n",
      "    Relationship properties are the following:\n",
      "    []\n",
      "    The relationships are the following:\n",
      "    ['(:Node)-[:CONNECTS]->(:Node)', '(:Node_2)-[:CONNECTS_2]->(:Node_2)']\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(schema_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158c65be",
   "metadata": {},
   "source": [
    "## Prompt to get Cypher query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a76e4325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def get_gpt3_response(curr_schema, question, api_key, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Send a request to the OpenAI Chat API and get a response from the model.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The user's question.\n",
    "        context (str): Contextual information to be passed to the model.\n",
    "        api_key (str): Your OpenAI API key.\n",
    "        model (str): The model version to use, default is \"gpt-3.5-turbo\".\n",
    "    \n",
    "    Returns:\n",
    "        str: The model's response.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are a useful assistant\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    new_context =  \"\"\"\n",
    "    \n",
    "    \"Human: Task:Generate Cypher statement to query a graph database.\\nInstructions:\\nUse only the provided \n",
    "    relationship types and properties in the schema.\\nDo not use any other relationship types or \n",
    "    properties that are not provided.\\nSchema:\\nNode properties are the following: \\n \n",
    "    {}\\n\n",
    "    Note: Do not include any explanations or apologies in your responses.\\n\n",
    "    Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "    \\nDo not include any text except the generated Cypher statement.\n",
    "    \\n\\nThe question is:\\n\\n{}\".\n",
    "    \"\"\".format(curr_schema,question)\n",
    "    \n",
    "    # Create the full prompt by combining the system prompt, context, and the user question\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": new_context}\n",
    "    ]\n",
    "    \n",
    "    ## Use the OpenAI Python client to send the request\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    # Extract the response text and return\n",
    "    return response.choices[0].message.content\n",
    "    #return response.choices[0].message['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dc65bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATCH path = (n:Node_2 {id: '2519'})-[:CONNECTS_2*]->(m:Node_2 {id: '10026'})\n",
      "RETURN count(path) as path_count\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "question = \"How many path exists from node 2519 to node 10026 for nodes of type node_2?\"\n",
    "response = get_gpt3_response(schema_str, question,  API_KEY, model = \"gpt-3.5-turbo\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d17452",
   "metadata": {},
   "source": [
    "## Executing the query in neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d46763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'path_count': 7}]\n"
     ]
    }
   ],
   "source": [
    "cypher_res = neo4j_query(response)\n",
    "print(cypher_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2ff185",
   "metadata": {},
   "source": [
    "## Making the second call to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1403303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def get_gpt3_response_2(prompt, question, api_key, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Send a request to the OpenAI Chat API and get a response from the model.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The user's question.\n",
    "        context (str): Contextual information to be passed to the model.\n",
    "        api_key (str): Your OpenAI API key.\n",
    "        model (str): The model version to use, default is \"gpt-3.5-turbo\".\n",
    "    \n",
    "    Returns:\n",
    "        str: The model's response.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are a useful assistant\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    new_context =  \"\"\"\n",
    "    \n",
    "    \"Human: You are an assistant that helps to form nice and human understandable answers\n",
    "    .\\nThe information part contains the provided information that you must use to construct an answer.\n",
    "    \\nThe provided information is authoritative, you must never doubt it or try to use your internal knowledge\n",
    "    to correct it.\\nMake the answer sound as a response to the question. \n",
    "    Do not mention that you based the result on the given information.\\n\n",
    "    If the provided information is empty, say that you don't know the answer.\n",
    "    \\nInformation:\\n{}\\n\\nQuestion: \\n]{}\\n\\nHelpful Answer:\"\n",
    "    \"\"\".format(prompt,question)\n",
    "    \n",
    "    # Create the full prompt by combining the system prompt, context, and the user question\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": new_context}\n",
    "    ]\n",
    "    \n",
    "    ## Use the OpenAI Python client to send the request\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    # Extract the response text and return\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47d76090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7 paths that exist from node 2519 to node 10026 for nodes of type node_2.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "question = \"How many path exists from node 2519 to node 10026 for nodes of type node_2?\"\n",
    "response_2 = get_gpt3_response_2(cypher_res, question,  API_KEY, model = \"gpt-3.5-turbo\")\n",
    "print(response_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d222e360",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e86b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "def neo4j_query(query: str, params: dict = {}) -> List[Dict[str, Any]]:\n",
    "\n",
    "    \"\"\"Query Neo4j database.\"\"\"\n",
    "    from neo4j.exceptions import CypherSyntaxError\n",
    "\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        try:\n",
    "            data = session.run(query, params)\n",
    "            return [r.data() for r in data]\n",
    "        except CypherSyntaxError as e:\n",
    "            raise ValueError(f\"Generated Cypher Statement is not valid\\n{e}\")\n",
    "            \n",
    "def refresh_schema() -> str:\n",
    "    \"\"\"\n",
    "    Refreshes the Neo4j graph schema information.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    node_properties_query = \"\"\"\n",
    "    CALL apoc.meta.data()\n",
    "    YIELD label, other, elementType, type, property\n",
    "    WHERE NOT type = \"RELATIONSHIP\" AND elementType = \"node\"\n",
    "    WITH label AS nodeLabels, collect({property:property, type:type}) AS properties\n",
    "    RETURN {labels: nodeLabels, properties: properties} AS output\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    rel_properties_query = \"\"\"\n",
    "    CALL apoc.meta.data()\n",
    "    YIELD label, other, elementType, type, property\n",
    "    WHERE NOT type = \"RELATIONSHIP\" AND elementType = \"relationship\"\n",
    "    WITH label AS nodeLabels, collect({property:property, type:type}) AS properties\n",
    "    RETURN {type: nodeLabels, properties: properties} AS output\n",
    "    \"\"\"\n",
    "\n",
    "    rel_query = \"\"\"\n",
    "    CALL apoc.meta.data()\n",
    "    YIELD label, other, elementType, type, property\n",
    "    WHERE type = \"RELATIONSHIP\" AND elementType = \"node\"\n",
    "    UNWIND other AS other_node\n",
    "    RETURN {start: label, type: property, end: toString(other_node)} AS output\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    node_properties = [el[\"output\"] for el in neo4j_query(node_properties_query)]\n",
    "    rel_properties = [el[\"output\"] for el in neo4j_query(rel_properties_query)]\n",
    "    relationships = [el[\"output\"] for el in neo4j_query(rel_query)]\n",
    "\n",
    "    structured_schema = {\n",
    "        \"node_props\": {el[\"labels\"]: el[\"properties\"] for el in node_properties},\n",
    "        \"rel_props\": {el[\"type\"]: el[\"properties\"] for el in rel_properties},\n",
    "        \"relationships\": relationships,\n",
    "    }\n",
    "    schema_str = f\"\"\"\n",
    "    Node properties are the following:\n",
    "    {node_properties}\n",
    "    Relationship properties are the following:\n",
    "    {rel_properties}\n",
    "    The relationships are the following:\n",
    "    {[f\"(:{el['start']})-[:{el['type']}]->(:{el['end']})\" for el in relationships]}\n",
    "    \"\"\"\n",
    "    \n",
    "    return schema_str\n",
    "\n",
    "def get_gpt3_response(curr_schema, question, api_key, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Send a request to the OpenAI Chat API and get a response from the model.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The user's question.\n",
    "        context (str): Contextual information to be passed to the model.\n",
    "        api_key (str): Your OpenAI API key.\n",
    "        model (str): The model version to use, default is \"gpt-3.5-turbo\".\n",
    "    \n",
    "    Returns:\n",
    "        str: The model's response.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are a usefule assistant but do not add any extra information or words unless specified\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    new_context =  \"\"\"\n",
    "    \n",
    "    \"Human: Task:Generate Cypher statement to query a graph database.\\nInstructions:\\nUse only the provided \n",
    "    relationship types and properties in the schema.\\nDo not use any other relationship types or \n",
    "    properties that are not provided.\\nSchema:\\nNode properties are the following: \\n \n",
    "    {}\\n\n",
    "    Note: Do not include any explanations or apologies in your responses.\\n\n",
    "    Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "    \\nDo not include any text except the generated Cypher statement.\n",
    "    \\n\\nThe question is:\\n\\n{}\".\n",
    "    \"\"\".format(curr_schema,question)\n",
    "    \n",
    "    # Create the full prompt by combining the system prompt, context, and the user question\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": new_context}\n",
    "    ]\n",
    "    \n",
    "    ## Use the OpenAI Python client to send the request\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    # Extract the response text and return\n",
    "    return response.choices[0].message.content\n",
    "    #return response.choices[0].message['content']\n",
    "\n",
    "\n",
    "def get_gpt3_response_2(prompt, question, api_key, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Send a request to the OpenAI Chat API and get a response from the model.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The user's question.\n",
    "        context (str): Contextual information to be passed to the model.\n",
    "        api_key (str): Your OpenAI API key.\n",
    "        model (str): The model version to use, default is \"gpt-3.5-turbo\".\n",
    "    \n",
    "    Returns:\n",
    "        str: The model's response.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are a useful assistant\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    new_context =  \"\"\"\n",
    "    \n",
    "    \"Human: You are an assistant that helps to form nice and human understandable answers\n",
    "    .\\nThe information part contains the provided information that you must use to construct an answer.\n",
    "    \\nThe provided information is authoritative, you must never doubt it or try to use your internal knowledge\n",
    "    to correct it.\\nMake the answer sound as a response to the question. \n",
    "    Do not mention that you based the result on the given information.\\n\n",
    "    Mention all node information using the id number.\n",
    "    If the provided information is empty, say that you don't know the answer.\n",
    "    \\nInformation:\\n{}\\n\\nQuestion: \\n]{}\\n\\nHelpful Answer:\"\n",
    "    \"\"\".format(prompt,question)\n",
    "    \n",
    "    # Create the full prompt by combining the system prompt, context, and the user question\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": new_context}\n",
    "    ]\n",
    "    \n",
    "    ## Use the OpenAI Python client to send the request\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    # Extract the response text and return\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lang_chain_custom(question,driver):\n",
    "    \n",
    "    curr_schema = refresh_schema()  \n",
    "    \n",
    "    ## Getting Cypher query\n",
    "    response = get_gpt3_response(curr_schema, question,  API_KEY, model = \"gpt-3.5-turbo\")\n",
    "    print('Cypher Query is',response)\n",
    "    \n",
    "    ## Interacting with neo4j\n",
    "    cypher_response = neo4j_query(response)\n",
    "    print('Neo4j answer is',cypher_response)\n",
    "    \n",
    "    ## Obtaining final answer\n",
    "    response_2 = get_gpt3_response_2(cypher_response, question,  API_KEY, model = \"gpt-3.5-turbo\")\n",
    "    \n",
    "    return response_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed3920e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher Query is MATCH p=(:Node_2 {id: '2519'})-[:CONNECTS_2*]->(:Node_2 {id: '10026'})\n",
      "RETURN count(p)\n",
      "Neo4j answer is [{'count(p)': 7}]\n",
      "There are 7 paths that exist from node 2519 to node 10026 for nodes of type node_2.\n"
     ]
    }
   ],
   "source": [
    "question = \"How many path exists from node 2519 to node 10026 for nodes of type node_2?\"\n",
    "response = lang_chain_custom(question,driver)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6018ba33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher Query is MATCH path = (start:Node_2 {id: '4651'})-[:CONNECTS_2*]->(end:Node_2 {id: '1136'})\n",
      "RETURN path\n",
      "Neo4j answer is [{'path': [{'country': 'AU', 'upstream': '9', 'downstream': '43', 'rank': '11319', 'id': '4651', 'org_name': 'CAT Telecom Public Company Limited', 'as_name': 'THAI-GATEWAY'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '1', 'downstream': '0', 'rank': '56868', 'id': '9737', 'org_name': 'TOT Public Company Limited', 'as_name': 'TOTNET-TH-AS-AP'}, 'CONNECTS_2', {'country': 'NL', 'upstream': '3', 'downstream': '25', 'rank': '108', 'id': '1136', 'org_name': 'KPN B.V.', 'as_name': 'KPN'}]}, {'path': [{'country': 'AU', 'upstream': '9', 'downstream': '43', 'rank': '11319', 'id': '4651', 'org_name': 'CAT Telecom Public Company Limited', 'as_name': 'THAI-GATEWAY'}, 'CONNECTS_2', {'country': 'NL', 'upstream': '3', 'downstream': '25', 'rank': '108', 'id': '1136', 'org_name': 'KPN B.V.', 'as_name': 'KPN'}]}]\n",
      "Node 4651 has two paths to node 1136 for nodes of type node_2. \n",
      "\n",
      "Path 1: \n",
      "Node 4651 connects to node 9737 (TOT Public Company Limited).\n",
      "Node 9737 connects to node 1136 (KPN B.V.).\n",
      "\n",
      "Path 2:\n",
      "Node 4651 also directly connects to node 1136 (KPN B.V.).\n",
      "\n",
      "These are the two paths from node 4651 to node 1136 for nodes of type node_2.\n"
     ]
    }
   ],
   "source": [
    "question = \"Return all paths from node 4651 to node 1136 for nodes of type node_2?\"\n",
    "response = lang_chain_custom(question,driver)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84390fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher Query is MATCH path = (start:Node_2 {id: '2519'})-[:CONNECTS_2*]->(end:Node_2 {id: '10026'})\n",
      "RETURN path\n",
      "Neo4j answer is [{'path': [{'country': 'JP', 'upstream': '3', 'downstream': '64', 'rank': '314', 'id': '2519', 'as_name': 'VECTANT'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '225', 'rank': '61', 'id': '1221', 'org_name': 'Telstra Corporation Limited', 'as_name': 'ASN-TELSTRA'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '0', 'rank': '9740', 'id': '38803', 'org_name': 'Wirefreebroadband Pty Ltd', 'as_name': 'WPL-AS-AP'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '8', 'downstream': '437', 'rank': '920', 'id': '4826', 'org_name': 'VOCUS PTY LTD', 'as_name': 'VOCUS-BACKBONE-AS'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '3', 'downstream': '193', 'rank': '3029', 'id': '4608', 'org_name': 'Asia Pacific Network Information Centre', 'as_name': 'APNIC-SERVICES'}, 'CONNECTS_2', {'country': 'AU', 'id': '10026', 'org_name': 'Telstra International Limited', 'as_name': 'TELSTRAGLOBAL'}]}, {'path': [{'country': 'JP', 'upstream': '3', 'downstream': '64', 'rank': '314', 'id': '2519', 'as_name': 'VECTANT'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '225', 'rank': '61', 'id': '1221', 'org_name': 'Telstra Corporation Limited', 'as_name': 'ASN-TELSTRA'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '0', 'rank': '9740', 'id': '38803', 'org_name': 'Wirefreebroadband Pty Ltd', 'as_name': 'WPL-AS-AP'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '225', 'rank': '61', 'id': '1221', 'org_name': 'Telstra Corporation Limited', 'as_name': 'ASN-TELSTRA'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '3', 'downstream': '193', 'rank': '3029', 'id': '4608', 'org_name': 'Asia Pacific Network Information Centre', 'as_name': 'APNIC-SERVICES'}, 'CONNECTS_2', {'country': 'AU', 'id': '10026', 'org_name': 'Telstra International Limited', 'as_name': 'TELSTRAGLOBAL'}]}, {'path': [{'country': 'JP', 'upstream': '3', 'downstream': '64', 'rank': '314', 'id': '2519', 'as_name': 'VECTANT'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '225', 'rank': '61', 'id': '1221', 'org_name': 'Telstra Corporation Limited', 'as_name': 'ASN-TELSTRA'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '0', 'rank': '9740', 'id': '38803', 'org_name': 'Wirefreebroadband Pty Ltd', 'as_name': 'WPL-AS-AP'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '225', 'rank': '61', 'id': '1221', 'org_name': 'Telstra Corporation Limited', 'as_name': 'ASN-TELSTRA'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '10', 'downstream': '458', 'rank': '555', 'id': '4637', 'org_name': 'Telstra International Limited', 'as_name': 'ASN-TELSTRA-GLOBAL'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '225', 'rank': '61', 'id': '1221', 'org_name': 'Telstra Corporation Limited', 'as_name': 'ASN-TELSTRA'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '3', 'downstream': '193', 'rank': '3029', 'id': '4608', 'org_name': 'Asia Pacific Network Information Centre', 'as_name': 'APNIC-SERVICES'}, 'CONNECTS_2', {'country': 'AU', 'id': '10026', 'org_name': 'Telstra International Limited', 'as_name': 'TELSTRAGLOBAL'}]}, {'path': [{'country': 'JP', 'upstream': '3', 'downstream': '64', 'rank': '314', 'id': '2519', 'as_name': 'VECTANT'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '225', 'rank': '61', 'id': '1221', 'org_name': 'Telstra Corporation Limited', 'as_name': 'ASN-TELSTRA'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '3', 'downstream': '193', 'rank': '3029', 'id': '4608', 'org_name': 'Asia Pacific Network Information Centre', 'as_name': 'APNIC-SERVICES'}, 'CONNECTS_2', {'country': 'AU', 'id': '10026', 'org_name': 'Telstra International Limited', 'as_name': 'TELSTRAGLOBAL'}]}, {'path': [{'country': 'JP', 'upstream': '3', 'downstream': '64', 'rank': '314', 'id': '2519', 'as_name': 'VECTANT'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '225', 'rank': '61', 'id': '1221', 'org_name': 'Telstra Corporation Limited', 'as_name': 'ASN-TELSTRA'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '10', 'downstream': '458', 'rank': '555', 'id': '4637', 'org_name': 'Telstra International Limited', 'as_name': 'ASN-TELSTRA-GLOBAL'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '225', 'rank': '61', 'id': '1221', 'org_name': 'Telstra Corporation Limited', 'as_name': 'ASN-TELSTRA'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '0', 'rank': '9740', 'id': '38803', 'org_name': 'Wirefreebroadband Pty Ltd', 'as_name': 'WPL-AS-AP'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '8', 'downstream': '437', 'rank': '920', 'id': '4826', 'org_name': 'VOCUS PTY LTD', 'as_name': 'VOCUS-BACKBONE-AS'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '3', 'downstream': '193', 'rank': '3029', 'id': '4608', 'org_name': 'Asia Pacific Network Information Centre', 'as_name': 'APNIC-SERVICES'}, 'CONNECTS_2', {'country': 'AU', 'id': '10026', 'org_name': 'Telstra International Limited', 'as_name': 'TELSTRAGLOBAL'}]}, {'path': [{'country': 'JP', 'upstream': '3', 'downstream': '64', 'rank': '314', 'id': '2519', 'as_name': 'VECTANT'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '225', 'rank': '61', 'id': '1221', 'org_name': 'Telstra Corporation Limited', 'as_name': 'ASN-TELSTRA'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '10', 'downstream': '458', 'rank': '555', 'id': '4637', 'org_name': 'Telstra International Limited', 'as_name': 'ASN-TELSTRA-GLOBAL'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '225', 'rank': '61', 'id': '1221', 'org_name': 'Telstra Corporation Limited', 'as_name': 'ASN-TELSTRA'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '0', 'rank': '9740', 'id': '38803', 'org_name': 'Wirefreebroadband Pty Ltd', 'as_name': 'WPL-AS-AP'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '225', 'rank': '61', 'id': '1221', 'org_name': 'Telstra Corporation Limited', 'as_name': 'ASN-TELSTRA'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '3', 'downstream': '193', 'rank': '3029', 'id': '4608', 'org_name': 'Asia Pacific Network Information Centre', 'as_name': 'APNIC-SERVICES'}, 'CONNECTS_2', {'country': 'AU', 'id': '10026', 'org_name': 'Telstra International Limited', 'as_name': 'TELSTRAGLOBAL'}]}, {'path': [{'country': 'JP', 'upstream': '3', 'downstream': '64', 'rank': '314', 'id': '2519', 'as_name': 'VECTANT'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '225', 'rank': '61', 'id': '1221', 'org_name': 'Telstra Corporation Limited', 'as_name': 'ASN-TELSTRA'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '10', 'downstream': '458', 'rank': '555', 'id': '4637', 'org_name': 'Telstra International Limited', 'as_name': 'ASN-TELSTRA-GLOBAL'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '225', 'rank': '61', 'id': '1221', 'org_name': 'Telstra Corporation Limited', 'as_name': 'ASN-TELSTRA'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '3', 'downstream': '193', 'rank': '3029', 'id': '4608', 'org_name': 'Asia Pacific Network Information Centre', 'as_name': 'APNIC-SERVICES'}, 'CONNECTS_2', {'country': 'AU', 'id': '10026', 'org_name': 'Telstra International Limited', 'as_name': 'TELSTRAGLOBAL'}]}]\n",
      "The paths from node 2519 to node 10026 for nodes of type node_2 are:\n",
      "- Path 1: [2519, 1221, 38803, 4826, 4608, 10026]\n",
      "- Path 2: [2519, 1221, 38803, 1221, 4608, 10026]\n",
      "- Path 3: [2519, 1221, 38803, 1221, 4637, 1221, 4608, 10026]\n",
      "- Path 4: [2519, 1221, 38803, 1221, 4637, 1221, 38803, 4826, 4608, 10026]\n",
      "- Path 5: [2519, 1221, 38803, 1221, 4637, 1221, 38803, 1221, 4608, 10026]\n",
      "- Path 6: [2519, 1221, 38803, 1221, 4637, 1221, 38803, 1221, 4637, 1221, 4608, 10026]\n",
      "\n",
      "Please note that there might be more paths available, but these are the ones provided in the information.\n"
     ]
    }
   ],
   "source": [
    "question = \"Return all paths from node 2519 to node 10026 for nodes of type node_2?\"\n",
    "response = lang_chain_custom(question,driver)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bcecd6",
   "metadata": {},
   "source": [
    "## Path questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8080697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher Query is MATCH path = (n:Node {id: '56203'})-[:CONNECTS*]->(m:Node {id: '38803'})\n",
      "RETURN path\n",
      "Neo4j answer is [{'path': [{'country': 'AU', 'id': '56203', 'org_name': 'Wirefreebroadband Pty Ltd', 'as_name': 'Gtelecom-AUSTRALIA'}, 'CONNECTS', {'country': 'AU', 'upstream': '2', 'downstream': '0', 'rank': '9740', 'id': '38803', 'org_name': 'Wirefreebroadband Pty Ltd', 'as_name': 'WPL-AS-AP'}]}]\n",
      "Yes, a path exists from node 56203 to node 38803. The path is as follows:\n",
      "56203 (Wirefreebroadband Pty Ltd - Gtelecom-AUSTRALIA) -> 38803 (Wirefreebroadband Pty Ltd - WPL-AS-AP)\n"
     ]
    }
   ],
   "source": [
    "question = \"Does a path exist from node 56203 to node 38803 for nodes of type node? If so what is the path?\"\n",
    "response = lang_chain_custom(question,driver)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "067c12f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher Query is MATCH path=(n:Node {id: \"2519\"})-[:CONNECTS*]->(m:Node {id: \"18144\"})\n",
      "RETURN path\n",
      "Neo4j answer is []\n",
      "I'm sorry, but as there is no provided information, I don't have the necessary data to determine if a path exists from node 2519 to node 18144 for nodes of type node, or what the path might be.\n"
     ]
    }
   ],
   "source": [
    "question = \"Does a path exist from node 2519 to node 18144 for nodes of type node? If so what is the path?\"\n",
    "response = lang_chain_custom(question,driver)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c684097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "def neo4j_query(query: str, params: dict = {}) -> List[Dict[str, Any]]:\n",
    "\n",
    "    \"\"\"Query Neo4j database.\"\"\"\n",
    "    from neo4j.exceptions import CypherSyntaxError\n",
    "\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        try:\n",
    "            data = session.run(query, params)\n",
    "            return [r.data() for r in data]\n",
    "        except CypherSyntaxError as e:\n",
    "            raise ValueError(f\"Generated Cypher Statement is not valid\\n{e}\")\n",
    "            \n",
    "def refresh_schema() -> str:\n",
    "    \"\"\"\n",
    "    Refreshes the Neo4j graph schema information.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    node_properties_query = \"\"\"\n",
    "    CALL apoc.meta.data()\n",
    "    YIELD label, other, elementType, type, property\n",
    "    WHERE NOT type = \"RELATIONSHIP\" AND elementType = \"node\"\n",
    "    WITH label AS nodeLabels, collect({property:property, type:type}) AS properties\n",
    "    RETURN {labels: nodeLabels, properties: properties} AS output\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    rel_properties_query = \"\"\"\n",
    "    CALL apoc.meta.data()\n",
    "    YIELD label, other, elementType, type, property\n",
    "    WHERE NOT type = \"RELATIONSHIP\" AND elementType = \"relationship\"\n",
    "    WITH label AS nodeLabels, collect({property:property, type:type}) AS properties\n",
    "    RETURN {type: nodeLabels, properties: properties} AS output\n",
    "    \"\"\"\n",
    "\n",
    "    rel_query = \"\"\"\n",
    "    CALL apoc.meta.data()\n",
    "    YIELD label, other, elementType, type, property\n",
    "    WHERE type = \"RELATIONSHIP\" AND elementType = \"node\"\n",
    "    UNWIND other AS other_node\n",
    "    RETURN {start: label, type: property, end: toString(other_node)} AS output\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    node_properties = [el[\"output\"] for el in neo4j_query(node_properties_query)]\n",
    "    rel_properties = [el[\"output\"] for el in neo4j_query(rel_properties_query)]\n",
    "    relationships = [el[\"output\"] for el in neo4j_query(rel_query)]\n",
    "\n",
    "    structured_schema = {\n",
    "        \"node_props\": {el[\"labels\"]: el[\"properties\"] for el in node_properties},\n",
    "        \"rel_props\": {el[\"type\"]: el[\"properties\"] for el in rel_properties},\n",
    "        \"relationships\": relationships,\n",
    "    }\n",
    "    schema_str = f\"\"\"\n",
    "    Node properties are the following:\n",
    "    {node_properties}\n",
    "    Relationship properties are the following:\n",
    "    {rel_properties}\n",
    "    The relationships are the following:\n",
    "    {[f\"(:{el['start']})-[:{el['type']}]->(:{el['end']})\" for el in relationships]}\n",
    "    \"\"\"\n",
    "    \n",
    "    return schema_str\n",
    "\n",
    "def get_gpt3_response(curr_schema, question, api_key, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Send a request to the OpenAI Chat API and get a response from the model.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The user's question.\n",
    "        context (str): Contextual information to be passed to the model.\n",
    "        api_key (str): Your OpenAI API key.\n",
    "        model (str): The model version to use, default is \"gpt-3.5-turbo\".\n",
    "    \n",
    "    Returns:\n",
    "        str: The model's response.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are a usefule assistant but do not add any extra information or words unless specified\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    new_context =  \"\"\"\n",
    "    \n",
    "    \"Human: Task:Generate Cypher statement to query a graph database.\\nInstructions:\\nUse only the provided \n",
    "    relationship types and properties in the schema.\\nDo not use any other relationship types or \n",
    "    properties that are not provided.\\nSchema:\\nNode properties are the following: \\n \n",
    "    {}\\n\n",
    "    Note: Do not include any explanations or apologies in your responses.\\n\n",
    "    Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "    \\nDo not include any text except the generated Cypher statement.\n",
    "    \\n\\nThe question is:\\n\\n{}\".\n",
    "    \"\"\".format(curr_schema,question)\n",
    "    \n",
    "    # Create the full prompt by combining the system prompt, context, and the user question\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": new_context}\n",
    "    ]\n",
    "    \n",
    "    ## Use the OpenAI Python client to send the request\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    # Extract the response text and return\n",
    "    return response.choices[0].message.content\n",
    "    #return response.choices[0].message['content']\n",
    "\n",
    "\n",
    "def get_gpt3_response_2(prompt, question, api_key, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Send a request to the OpenAI Chat API and get a response from the model.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The user's question.\n",
    "        context (str): Contextual information to be passed to the model.\n",
    "        api_key (str): Your OpenAI API key.\n",
    "        model (str): The model version to use, default is \"gpt-3.5-turbo\".\n",
    "    \n",
    "    Returns:\n",
    "        str: The model's response.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are a useful assistant\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    new_context =  \"\"\"\n",
    "    \n",
    "    \"Human: You are an assistant that helps to form nice and human understandable answers\n",
    "    .\\nThe information part contains the provided information that you must use to construct an answer.\n",
    "    \\nThe provided information is authoritative, you must never doubt it or try to use your internal knowledge\n",
    "    to correct it.\\nMake the answer sound as a response to the question. \n",
    "    Do not mention that you based the result on the given information.\\n\n",
    "    Mention all node information using the id number.\n",
    "    If the question is to check whether a path exists or not and if the information is empty\n",
    "    then return that path do not exist .\\n   \n",
    "    In all other cases, If the provided information is empty, say that you don't know the answer.\\n\n",
    "    \\nInformation:\\n{}\\n\\nQuestion: \\n]{}\\n\\nHelpful Answer:\"\n",
    "    \"\"\".format(prompt,question)\n",
    "    \n",
    "    # Create the full prompt by combining the system prompt, context, and the user question\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": new_context}\n",
    "    ]\n",
    "    \n",
    "    ## Use the OpenAI Python client to send the request\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    # Extract the response text and return\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lang_chain_custom(question,driver):\n",
    "    \n",
    "    curr_schema = refresh_schema()  \n",
    "    \n",
    "    ## Getting Cypher query\n",
    "    response = get_gpt3_response(curr_schema, question,  API_KEY, model = \"gpt-3.5-turbo\")\n",
    "    print('Cypher Query is',response)\n",
    "    \n",
    "    ## Interacting with neo4j\n",
    "    cypher_response = neo4j_query(response)\n",
    "    print('Neo4j answer is',cypher_response)\n",
    "    \n",
    "    ## Obtaining final answer\n",
    "    response_2 = get_gpt3_response_2(cypher_response, question,  API_KEY, model = \"gpt-3.5-turbo\")\n",
    "    \n",
    "    return response_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9880af7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher Query is MATCH path = (n1:Node {id: 2519})-[:CONNECTS*]->(n2:Node {id: 18144})\n",
      "RETURN path;\n",
      "Neo4j answer is []\n",
      "No, I'm sorry, I don't have any information to determine whether a path exists from node 2519 to node 18144 for nodes of type node. Since the information is empty, I cannot provide the path for you.\n"
     ]
    }
   ],
   "source": [
    "question = \"Does a path exist from node 2519 to node 18144 for nodes of type node? If so what is the path?\"\n",
    "response = lang_chain_custom(question,driver)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a5f581",
   "metadata": {},
   "source": [
    "## Shortest Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ba85189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher Query is MATCH (n1:Node {id: \"2519\"}), (n2:Node {id: \"10026\"})\n",
      "MATCH path = shortestPath((n1)-[:CONNECTS*]-(n2))\n",
      "RETURN [node in nodes(path) | node.id] AS ShortestPath\n",
      "Neo4j answer is [{'ShortestPath': ['2519', '10026']}]\n",
      "The shortest path from node 2519 to node 10026 for nodes of type node is:\n",
      "2519 -> 10026\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"What is the shortest path from node 2519 to node 10026 for nodes of type node? Refer all nodes\n",
    "with respect to their Ids in the final answer\"\"\" \n",
    "response = lang_chain_custom(question,driver)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17ab0dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher Query is MATCH p=shortestPath((n1:Node_2 {id: '2519'})-[:CONNECTS_2*]-(n2:Node_2 {id: '10026'}))\n",
      "RETURN nodes(p) AS path_nodes, relationships(p) AS path_relationships, length(p) AS path_length\n",
      "\n",
      "\n",
      "Neo4j answer is [{'path_nodes': [{'country': 'JP', 'upstream': '3', 'downstream': '64', 'rank': '314', 'id': '2519', 'as_name': 'VECTANT'}, {'country': 'AU', 'upstream': '2', 'downstream': '225', 'rank': '61', 'id': '1221', 'org_name': 'Telstra Corporation Limited', 'as_name': 'ASN-TELSTRA'}, {'country': 'AU', 'upstream': '3', 'downstream': '193', 'rank': '3029', 'id': '4608', 'org_name': 'Asia Pacific Network Information Centre', 'as_name': 'APNIC-SERVICES'}, {'country': 'AU', 'id': '10026', 'org_name': 'Telstra International Limited', 'as_name': 'TELSTRAGLOBAL'}], 'path_relationships': [({'country': 'JP', 'upstream': '3', 'downstream': '64', 'rank': '314', 'id': '2519', 'as_name': 'VECTANT'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '2', 'downstream': '225', 'rank': '61', 'id': '1221', 'org_name': 'Telstra Corporation Limited', 'as_name': 'ASN-TELSTRA'}), ({'country': 'AU', 'upstream': '2', 'downstream': '225', 'rank': '61', 'id': '1221', 'org_name': 'Telstra Corporation Limited', 'as_name': 'ASN-TELSTRA'}, 'CONNECTS_2', {'country': 'AU', 'upstream': '3', 'downstream': '193', 'rank': '3029', 'id': '4608', 'org_name': 'Asia Pacific Network Information Centre', 'as_name': 'APNIC-SERVICES'}), ({'country': 'AU', 'upstream': '3', 'downstream': '193', 'rank': '3029', 'id': '4608', 'org_name': 'Asia Pacific Network Information Centre', 'as_name': 'APNIC-SERVICES'}, 'CONNECTS_2', {'country': 'AU', 'id': '10026', 'org_name': 'Telstra International Limited', 'as_name': 'TELSTRAGLOBAL'})], 'path_length': 3}]\n",
      "The shortest path from node 2519 to node 10026 for nodes of type node_2 is as follows:\n",
      "\n",
      "2519 -> 1221 -> 4608 -> 10026\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"What is the shortest path from node 2519 to node 10026 for nodes of type node_2? Refer all nodes\n",
    "with respect to their Ids in the final answer\"\"\" \n",
    "response = lang_chain_custom(question,driver)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8a8adc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher Query is MATCH (n:Node)-[:CONNECTS]->()\n",
      "WHERE n.id = '10026'\n",
      "RETURN n.id, COUNT(*) AS outDegree\n",
      "ORDER BY n.id\n",
      "Neo4j answer is [{'n.id': '10026', 'outDegree': 4}]\n",
      "The out degree of node 10026 is 4.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"What is the out degree of node 10026? Refer all nodes\n",
    "with respect to their Ids in the final answer\"\"\" \n",
    "response = lang_chain_custom(question,driver)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59efa9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
